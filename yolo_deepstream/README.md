# Yolo DeepStream

##  Description

This repo have 4 parts:
### 1) yolov7_qat
In [yolov7_qat](yolov7_qat), We use [TensorRT's pytorch quntization tool](https://github.com/NVIDIA/TensorRT/tree/main/tools/pytorch-quantization) to Finetune training QAT yolov7 from the pre-trained weight. 
Finally we get the same performance of PTQ in TensorRT on Jetson OrinX. And the accuracy(mAP) of the model only dropped a little.

### 2) tensorrt_yolo
In [tensorrt_yolo](tensorrt_yolo), We provide a standalone c++ yolov7-app sample here. You can use trtexec to convert FP32 onnx models or QAT-int8 models exported from repo [yolov7_qat](yolov7_qat) to trt-engines. And set the trt-engine as yolov7-app's input. It can do detections on images/videos. Or test mAP on COCO dataset. It also support [yolov8](#onnx-model-list) and [yolov9](#onnx-model-list) models.

### 3) deepstream_yolo
In [deepstream_yolo](deepstream_yolo), This sample shows how to integrate YOLO models with customized output layer parsing for detected objects with DeepStreamSDK.

## Performance

Below table shows the end-to-end performance of processing 1080p videos with this sample application.
- Testing Device : 

  1. Jetson AGX Orin 64GB(PowerMode:MAXN + GPU-freq:1.3GHz + CPU:12-core-2.2GHz)

  2. Tesla T4

- Testing Models
  1. Yolov7 models and calibration file can be found in sub dir: [yolov7_qat](./yolov7_qat/README.md#description)
  2. Yolov8s model and calibration files can be found here: [model list](#onnx-model-list)
  3. Yolov9s model can be generated by the method in [yolov9 model generation](deepstream_yolo/#yolov9)
  2. Yolov11s model can be generated by the method in: [yolov11s model generation](deepstream_yolo/#yolov11s)


  #### Performance in Jetson Thor

  The data in the following table are tested with scaling-compute-hw=1.

  |Model |precision      | Batch Size | Number <br>of streams | trtexec FPS| deepstream-app FPS<br>with cuda-post-process | mAP<sup>val<br>0.5:0.95 |
  |--------------|-----------    |-----------    |----------------- | -----------|----------- | --------- |
  |yolov4 |    FP16         |  1               |     1      |       278  | 52   | 51.13 |
  |yolov7 |    FP16         |  1               |     1      |       600  | 60   | 51.13 |
  |yolov8s |  FP16         |  1               |     1      |   1097      | 64  |44.5|
  |yolov9s|    FP16         |  1               |     1      |  582    |  59   |46.8|
  |yolov11s|  FP16         |  1               |     1      | 977    | 63    | 46.5|
  |yolov4  |  FP16         |  16              |    16      |       391  | 384   |51.13|
  |yolov7  |  FP16         |  16              |    16      |       740  | 656   |51.13|
  |yolov8s |  FP16         |  16              |    16      |   1061      | 944  |44.5|
  |yolov9s|   FP16         |  16              |    16      |  788    |  656   |46.8|
  |yolov11s|  FP16         |  16              |    16      | 1197    |  768   |46.5|

  - Note: Jetson Thor does not support DLA

  The data in the following table are tested with scaling-compute-hw=2.

  |Model |precision      | Batch Size | Number <br>of streams | trtexec FPS| deepstream-app FPS<br>with cuda-post-process | mAP<sup>val<br>0.5:0.95 |
  |--------------|-----------    |-----------    |----------------- | -----------|----------- | --------- |
  |yolov4 |    FP16         |  1               |     1      |       278  | 52   | 51.13 |
  |yolov7 |    FP16         |  1               |     1      |       600  | 61   | 51.13 |
  |yolov8s |  FP16         |  1               |     1      |   1097      | 63  |44.5|
  |yolov9s|    FP16         |  1               |     1      |  582    |  60   |46.8|
  |yolov11s|  FP16         |  1               |     1      | 977    | 61    | 46.5|
  |yolov4  |  FP16         |  16              |    16      |       391  | 368   |51.13|
  |yolov7  |  FP16         |  16              |    16      |       740  | 608   |51.13|
  |yolov8s |  FP16         |  16              |    16      |   1061      | 944  |44.5|
  |yolov9s|   FP16         |  16              |    16      |  788    |  608   |46.8|
  |yolov11s|  FP16         |  16              |    16      | 1197    |  768   |46.5|

  #### Performance in Tegra T4

  The data in the following table are tested with scaling-compute-hw=1.
  
  |Model |precision      | Batch Size | Number <br>of streams | trtexec FPS| deepstream-app FPS<br>with cuda-post-process | mAP<sup>val<br>0.5:0.95 |
  |--------------|-----------|-----------|----------------- | -----------|----------- | ---------|
  |yolov7|  FP16  |  1          |     1      |     208    | 58       | 51.13 |
  |yolov8s| FP16  |  1          |     1      |   1064     | 70       |  44.5 |
  |yolov9s| FP16  |  1          |     1      |  326    | 58    | 46.8 |
  |yolov11s| FP16 |  1          |     1      | 1132 |  64   | 46.5 |
  |yolov7|  FP16  |  16         |    16      |     305    | 304       | 51.13 |
  |yolov8s| FP16  |  16         |    16      |   1590     | 752      | 44.5 |
  |yolov9s| FP16  |  16         |    16      |  688    | 368    | 46.8 |
  |yolov11s| FP16 |  16         |    16      | 1532 | 688 | 46.5 |


 - Note: trtexec cudaGraph not enabled as deepstream not support cudaGraph


## Onnx model list

we provide the following onnx models


| model name  | calibrationFile      |Hardware              | resolution  | precision | mAP<sup>val<br>0.5:0.95 |
|-----------  |-----------           |-----------------     | ------      | ------      |------      |
|  [yolov7_ptq_640.onnx](https://nvidia.box.com/shared/static/rlv3buq7sei2log2d3beyg1jhjyw59hn)         |  explict quant model with QDQ nodes                |  gpu                   |     batch x 3 x 640 x 640       |  int8 |51.00 |
|  [yolov7.onnx](https://nvidia.box.com/shared/static/rmh8rttesg4cgrysb2qm12udpvd95as1)         |  -                |  gpu                   |     batch x 3 x 640 x 640       |  fp16 | 	51.24|
|  [yolov7_qat_640.onnx](https://nvidia.box.com/shared/static/v1ze885p35hfjl96xtw8s0xbcpv64tfr)         |      explict quant model with QDQ            |  gpu                  |    batch x 3 x 640 x 640       |  int8 | 51.13 |
|  [yolov8s_DAT_640_noqdq.onnx](https://nvidia.box.com/shared/static/ownxazhmtpnlo3jvbkx4r62ffccm8hu5)     |  [yolov8s_DAT_precision_config_calib.cache](https://nvidia.box.com/shared/static/6bua0bo57cb6s44048os9qq9i1xjw5u1)                |  dla                  |     1 x 3 x 640 x 640       | int8 |44.6|
|  [yolov8s_640_dynamic.onnx](https://nvidia.box.com/shared/static/yie26fuadn2wdm21bqqagbjat68ih38p)     |  [yolov8s_gpu_precision_config_calib.cache](https://nvidia.box.com/shared/static/041fltrp4i0u8nv37fy3oj31453bjbp3)                |  gpu                  |     batch x 3 x 640 x 640       | int8/fp16 |44.5/44.9 |
|  [yolov9-s-converted.sim.trans.onnx](https://nvidia.box.com/shared/static/dzch7bx0xlap4hoc5nk9huy72w33wbc9)     |     -            |  gpu                 |     1 x 3 x 640 x 640       | fp16 |46.8|
|  [yolov11s_qat_int8_672_dynamic.onnx](https://nvidia.box.com/shared/static/87pt9tlgx588l9j9a9wfdk2yjljjrffn)         |      explict quant model with QDQ            |  gpu                  |    batch x 3 x 672 x 672       |  int8 | 46.5 |


## Code structure
```bash
├── CLA.md
├── deepstream_yolo
│   ├── append_transpose_yolov8_v9.py
│   ├── build_DLA_engine.sh
│   ├── config_infer_primary_yoloV4.txt     # config file for yolov4 model
│   ├── config_infer_primary_yoloV7.txt     # config file for yolov7 model
│   ├── config_infer_primary_yoloV8_dla.txt # config file for yolov8 for Jetson DLA model
│   ├── config_infer_primary_yoloV8.txt     # config file for yolov8 model
│   ├── config_infer_primary_yoloV9.txt     # config file for yolov9 model
|   ├── config_infer_primary_yoloV11.txt    # config file for yolov11 model
│   ├── deepstream_app_config_yolo.txt
│   ├── labels.txt                          # labels for coco detection
│   ├── nvdsinfer_custom_impl_Yolo          # output layer parsing functions for detected objects for the Yolo model.
│   │   ├── Makefile
│   │   ├── nvdsparsebbox_Yolo.cpp
│   │   └── nvdsparsebbox_Yolo_cuda.cu
│   └── README.md
├── LICENSE.md
├── README.md
├── tensorrt_yolo
│   ├── CMakeLists.txt
│   ├── imgs    # the demo images
│   │   ├── horses.jpg
│   │   └── zidane.jpg
│   ├── README.md
│   ├── samples
│   │   ├── detect.cpp         # detection app for images detection
│   │   ├── validate_coco.cpp  # validate coco dataset app
│   │   └── video_detect.cpp   # detection app for video detection
│   ├── src
│   │   ├── argsParser.cpp     # argsParser helper class for commandline parsing
│   │   ├── argsParser.h       # argsParser helper class for commandline parsing
│   │   ├── tools.h            # helper function for yolo class
│   │   ├── Yolo.cpp           # Class Yolo
│   │   └── Yolo.h             # Class Yolo
│   └── test_coco_map.py       # tool for test coco map with json file
└── yolov7_qat
    ├── doc
    │   ├── Guidance_of_QAT_performance_optimization.md  # guidance for Q&DQ insert and placement for pytorch-quantization tool
    │   └── imgs      # the demo images
    │       ├── int8_q_recommended_procedure.png
    │       ├── monkey-patch-qat-conv-fp16-issue_ptqonnx.png
    │       ├── monkey-patch-qat-conv-fp16-issue_ptq.png
    │       ├── monkey-patch-qat-conv-fp16-issue_qatonnx_edit.png
    │       ├── monkey-patch-qat-conv-fp16-issue_qatonnx.png
    │       ├── monkey-patch-qat-conv-fp16-issue_qat.png
    │       ├── monkey-patch-qat-maxpooling-qat.png
    │       ├── QATConv.png
    │       └── QATFlow.png
    ├── quantization
    │   ├── quantize.py    # helper class for quantize yolov7 model
    │   └── rules.py       # rules for Q&DQ nodes insert and restrictions
    ├── README.md
    └── scripts
        ├── detect-trt.py    # detect a image with tensorrt engine
        ├── draw-engine.py   # draw tensorrt engine to graph
        ├── eval-trt.py      # the script for evalating tensorrt mAP
        ├── eval-trt.sh      # the command lne script for evaluating tensorrt mAP
        ├── qat.py           # main function for QAT and PTQ
        ├── qat-yolov5.py
        ├── quantize_utils.py
        └── trt-int8.py      # tensorrt build-in calibration
```
