# Yolo DeepStream

##  Description

This repo have 4 parts:
### 1) yolov7_qat
In [yolov7_qat](yolov7_qat), We use [TensorRT's pytorch quntization tool](https://github.com/NVIDIA/TensorRT/tree/main/tools/pytorch-quantization) to Finetune training QAT yolov7 from the pre-trained weight. 
Finally we get the same performance of PTQ in TensorRT on Jetson OrinX. And the accuracy(mAP) of the model only dropped a little.

### 2) tensorrt_yolo
In [tensorrt_yolo](tensorrt_yolo), We provide a standalone c++ yolov7-app sample here. You can use trtexec to convert FP32 onnx models or QAT-int8 models exported from repo [yolov7_qat](yolov7_qat) to trt-engines. And set the trt-engine as yolov7-app's input. It can do detections on images/videos. Or test mAP on COCO dataset. It also support [yolov8](#onnx-model-list) and [yolov9](#onnx-model-list) models.

### 3) deepstream_yolo
In [deepstream_yolo](deepstream_yolo), This sample shows how to integrate YOLO models with customized output layer parsing for detected objects with DeepStreamSDK.

## Performance

Below table shows the end-to-end performance of processing 1080p videos with this sample application.
- Testing Device : 

  1. Jetson AGX Orin 64GB(PowerMode:MAXN + GPU-freq:1.3GHz + CPU:12-core-2.2GHz)

  2. Tesla T4

- Testing Models
  1. Yolov7 models and calibration file can be found in sub dir: [yolov7_qat](./yolov7_qat/README.md#description)
  2. Yolov8s model and calibration files can be found here: [model list](#onnx-model-list)
  3. Yolov9s model can be generated by the method in [yolov9 model generation](deepstream_yolo/#yolov9)

  #### Performance in Jetson AGX Orin
  |Model |precision      |Number <br>of streams | Batch Size | trtexec FPS| deepstream-app FPS<br>with cuda-post-process |
  |--------------|-----------    |-----------    |----------------- | -----------|----------- |
  |yolov7 |    FP16         |  1               |     1      |       126  | 124       |
  |yolov7 |    FP16         |  16              |    16      |       162  | 145       |
  |yolov7 |    Int8         |  1               |     1      |       180  | 175       |
  |yolov7 |    Int8         |  16              |    16      |       264  | 264       |
  |yolov8s |    FP16         |    1               |     1      |   309      | 268  |
  |yolov8s |    FP16         |  16              |    16      |   467      | 438  |
  |yolov8s |  Int8         |  1               |     1      |   425      | 360  |
  |yolov8s |  Int8         |  16              |    16      |   800      | 719  |
  |yolov8s |   Int8 *       |  1               |     1      |   243      | 201 |
  |yolov9s|   FP16         |  1               |     1      |  212    |  180   |
  |yolov9s|   FP16         |  16              |    16      |  341    |  324   |
  |yolov9s|    Int8         |  1               |     1      |  269    |  230   |
  |yolov9s|   Int8         |  16              |    16      |  519    |  461   |

  - Note: The Int8 model on Jetson DLA


  #### Performance in Tegra T4
  |Model |precision      |Number <br>of streams | Batch Size | trtexec FPS| deepstream-app FPS<br>with cuda-post-process |
  |--------------|-----------|-----------|----------------- | -----------|----------- |
  |yolov7| FP16   |  1          |     1      |      132   | 125       |
  |yolov7| FP16   |  16         |    16      |      169   | 169       |
  |yolov7|  Int8  |  1          |     1      |     208    | 170       |
  |yolov7|  Int8  |  16         |    16      |     305    | 300       |
  |yolov8s| FP16  |  1          |     1      |   752      | 211       | 
  |yolov8s| FP16  |  16         |    16      |   796      | 738       | 
  |yolov8s| Int8  |  1          |     1      |   1064     | 285       | 
  |yolov8s| Int8  |  16         |    16      |   1590     | 1337      |
  |yolov9s| FP16  |  1          |     1      |   254   | 240    | 
  |yolov9s| FP16  |  16         |    16      |   379   | 376    | 
  |yolov9s| Int8  |  1          |     1      |  326    | 309    | 
  |yolov9s| Int8  |  16         |    16      |  688    | 608    | 


 - Note: * trtexec cudaGraph not enabled as deepstream not support cudaGraph


## Onnx model list

The following onnx models are provided


| model name  | calibrationFile      |Hardware              | resolution  | precision | mAP<sup>val<br>0.5:0.95 |
|-----------  |-----------           |-----------------     | ------      | ------      |------      |
|  [yolov7_ptq_640.onnx](https://nvidia.box.com/shared/static/rlv3buq7sei2log2d3beyg1jhjyw59hn)         |  explict quant model with QDQ nodes                |  gpu                   |     batch x 3 x 640 x 640       |  int8 |51.00 |
|  [yolov7.onnx](https://nvidia.box.com/shared/static/rmh8rttesg4cgrysb2qm12udpvd95as1)         |  -                |  gpu                   |     batch x 3 x 640 x 640       |  fp16 | 	51.24|
|  [yolov7_qat_640.onnx](https://nvidia.box.com/shared/static/v1ze885p35hfjl96xtw8s0xbcpv64tfr)         |      explict quant model with QDQ            |  gpu                  |    batch x 3 x 640 x 640       |  int8 | 51.13 |
|  [yolov8s_DAT_640_noqdq.onnx](https://nvidia.box.com/shared/static/ownxazhmtpnlo3jvbkx4r62ffccm8hu5)     |  [yolov8s_DAT_precision_config_calib.cache](https://nvidia.box.com/shared/static/6bua0bo57cb6s44048os9qq9i1xjw5u1)                |  dla                  |     1 x 3 x 640 x 640       | int8 |44.6|
|  [yolov8s_640_dynamic.onnx](https://nvidia.box.com/shared/static/yie26fuadn2wdm21bqqagbjat68ih38p)     |  [yolov8s_gpu_precision_config_calib.cache](https://nvidia.box.com/shared/static/041fltrp4i0u8nv37fy3oj31453bjbp3)                |  gpu                  |     batch x 3 x 640 x 640       | int8/fp16 |44.5/44.9 |
|  [yolov9-s-converted.sim.trans.onnx](https://nvidia.box.com/shared/static/dzch7bx0xlap4hoc5nk9huy72w33wbc9)     |     -            |  gpu                 |     1 x 3 x 640 x 640       | fp16 |46.8|


## Code structure
```bash
├── CLA.md
├── deepstream_yolo
│   ├── append_transpose_yolov8_v9.py
│   ├── build_DLA_engine.sh
│   ├── config_infer_primary_yoloV4.txt     # config file for yolov4 model
│   ├── config_infer_primary_yoloV7.txt     # config file for yolov7 model
│   ├── config_infer_primary_yoloV8_dla.txt # config file for yolov8 for Jetson DLA model
│   ├── config_infer_primary_yoloV8.txt     # config file for yolov8 model
│   ├── config_infer_primary_yoloV9.txt     # config file for yolov9 model
│   ├── deepstream_app_config_yolo.txt
│   ├── labels.txt                          # labels for coco detection
│   ├── nvdsinfer_custom_impl_Yolo          # output layer parsing functions for detected objects for the Yolo model.
│   │   ├── Makefile
│   │   ├── nvdsparsebbox_Yolo.cpp
│   │   └── nvdsparsebbox_Yolo_cuda.cu
│   └── README.md
├── LICENSE.md
├── README.md
├── tensorrt_yolo
│   ├── CMakeLists.txt
│   ├── imgs    # the demo images
│   │   ├── horses.jpg
│   │   └── zidane.jpg
│   ├── README.md
│   ├── samples
│   │   ├── detect.cpp         # detection app for images detection
│   │   ├── validate_coco.cpp  # validate coco dataset app
│   │   └── video_detect.cpp   # detection app for video detection
│   ├── src
│   │   ├── argsParser.cpp     # argsParser helper class for commandline parsing
│   │   ├── argsParser.h       # argsParser helper class for commandline parsing
│   │   ├── tools.h            # helper function for yolo class
│   │   ├── Yolo.cpp           # Class Yolo
│   │   └── Yolo.h             # Class Yolo
│   └── test_coco_map.py       # tool for test coco map with json file
└── yolov7_qat
    ├── doc
    │   ├── Guidance_of_QAT_performance_optimization.md  # guidance for Q&DQ insert and placement for pytorch-quantization tool
    │   └── imgs      # the demo images
    │       ├── int8_q_recommended_procedure.png
    │       ├── monkey-patch-qat-conv-fp16-issue_ptqonnx.png
    │       ├── monkey-patch-qat-conv-fp16-issue_ptq.png
    │       ├── monkey-patch-qat-conv-fp16-issue_qatonnx_edit.png
    │       ├── monkey-patch-qat-conv-fp16-issue_qatonnx.png
    │       ├── monkey-patch-qat-conv-fp16-issue_qat.png
    │       ├── monkey-patch-qat-maxpooling-qat.png
    │       ├── QATConv.png
    │       └── QATFlow.png
    ├── quantization
    │   ├── quantize.py    # helper class for quantize yolov7 model
    │   └── rules.py       # rules for Q&DQ nodes insert and restrictions
    ├── README.md
    └── scripts
        ├── detect-trt.py    # detect a image with tensorrt engine
        ├── draw-engine.py   # draw tensorrt engine to graph
        ├── eval-trt.py      # the script for evalating tensorrt mAP
        ├── eval-trt.sh      # the command lne script for evaluating tensorrt mAP
        ├── qat.py           # main function for QAT and PTQ
        ├── qat-yolov5.py
        ├── quantize_utils.py
        └── trt-int8.py      # tensorrt build-in calibration
```
